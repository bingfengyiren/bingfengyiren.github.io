### 经纪人的24h随身助理-小贝咨询助手

大家我今天的分享主题是经纪人的24h随身助理-小贝咨询助手。小贝咨询助手是我们在IM场景下为经纪人提供的一个作业辅助工作。

#### 自我介绍

以下是我的个人介绍，我2015年毕业于武汉大学，先后在微博、小米从事内容推荐相关工作，2018年加入贝壳负责智能审核、智能客服以及语义理解等工作。

#### 1. 背景（回答：什么是咨询助手，为什么做咨询助手)

【此处应有1图描述咨询助手在】客->房->经纪人 如果通过咨询助手实现连接

贝壳致力于构建服务2亿家庭的品质居住平台，而随着经纪人的增加，不同经纪人之间的作业方差会越来越大，所以小贝咨询助手承载的就是通过学习优秀经纪人的作业流程、作业标准从而实现经纪人赋能，降低经纪人之间的作业方差。

【此处应有1图描述咨询助手各模块整体关系】

把咨询助手的整个架构展开来看的话，同样也不会跳脱对话系统几个大的模块，NLU(自然语言理解)、DM (对话管理,包括DST(对话状态追踪)以及DP(对话策略))、NLG(自然语言生成)、QA几个大的模块。

【此处举个栗子，并附上推送房源，房源详情的动作】

在我们的业务场景中，咨询助手要执行的动作有回答详情、推荐房源、询问需求、约带看等大概十几类，但是最重要的两个动作是：找房以及回答用户关于房屋信息的询问，找房是当在执行一个对话任务的时候，如果用户输入“推荐个海淀区500万的房子”或者根据当前的对话状态(Dialog State)判定可以是否可以推送房源，如果可以就会触发推送房源的动作，推送房源以后用户一般会根据自己的关注点询问房源的一些基本信息，比如：房屋所在楼层、房子是否有议价空间、房子是否随时可看等等。下面我们就详细介绍下NLU、DM、QaBot几个核心模块的构建以及技术选型与踩坑，我们对话系统中不同模块的构建情况。（可以在不同的例子的时候高亮不同的模块）。

#### 2. NLU

NLU是整个对话系统非常核心的模块，主要为下游任务提供意图、槽位、指代、情感、句式等基础特征和信息。意图和槽位是NLU中较为核心的模块，时间有限，这里也主要介绍下我们在这两个模块的建设。

##### 2.1 意图识别

意图的建设主要包含几个重要过程意图体系构建、语料集构建、模型选择、效果迭代。

【此处放意图体系构建架构+示例意图体系】

在一个复杂业务场景下意图体系的构建是一件非常费时费力的事情，意图体系构建主要依赖数据聚类、专家经验的总结与迭代逐步趋于稳定，在数据聚类过程由于不同的句式最终的意图通常也是不同的，因此为了提高聚类簇的准确性，通常会把数据按照句式划分，分别聚类。这里给大家展示一下我们意图体系的一部分，整体的意图体系会有300多个意图。

【此处放训练集构建的循环流程】

有了意图体系，下一步就是快速构建每个意图的训练语料集，为了加速这个过程我们构建智能标注平台，这个过程分为两个阶段，第一阶段是完全没有监督语料的时候，通过标注写一些规则从原始语料中过滤出符合意图含义的语料进行标注，第一阶段我们一般为每个意图生产50+条语料，第二阶段就是根据第一阶段语料训练的模型对未标注语料进行预打标，然后通过主动学习的方式挖掘出混淆语料进行标注，就这样循环迭代一直到达到业务准召目标。在训练数据构建的过程中，不可避免的会使得训练集的语料变得不那么纯净，从而影响模型的效果，这里可以尝试一些数据清洗的一些方式，比如：置信度学习。

【此处放意图识别的系统结构】

意图识别是个系统工程，并不是单一模型就可以解决所有业务问题的，所以整个意图的识别过程包含两个步骤：第一步是规则引擎，通过对历史用户的搜索数据分析，把高频出现的一些case或者满足某些范式的一些pattern加载入系统，从而保证系统在高频case上的识别准确率和稳定性，第二步是模型识别，模型识别相对泛华能力更强，但是每次模型的更新带来的不确定性也会更高，这里我们的实现思路是预训练+模型压缩，首先通过Robert-large版本进行finetuning得到large版本的意图识别结果，然后让albert-tiny版本的预训练模型同时去学习large版本的soft logits和标注数据的hard logits得到最终的线上模型。为了避免相同含义的槽对文本含义的影响，在模型输入时通常会做些一些预处理操作，比如把“推荐个180w的房子”，处理成 “推荐个price的房子”。

【此处放从Robert-large 到 albert-tiny 版本知识蒸馏过程】

这个过程中也可以通过数据增强的方式来来优化算法的识别效果，现在常用的数据增强方式有EDA、回译以及UDA，UDA是google 2019年提出来半监督学习方法，但是通过数据增强更多时候增加的意图的召回率，准确率一般都会有所下降。最后再说一下很多的业务场景中都会采用意图槽位联合学习的方法，我们这里没有采用的原因

【此处放意图效果优化的整体体系】

对于一个庞大的意图体系，效果优化也绝不是一件简单的事情，为了聚焦重点，我们设计了一个收益公式，来辅助我们确定每次要重点优化的意图，同时又可以保证每次的优化都能拿到最高的收益。

<center>				

$$ gain = \left\{ \begin{array}{**l**} \prod_{i=0}^n(obj_{i}-cur_{i})\times percent\\ 0 , & if \prod_{i=0}^n(obj_{i}-cur_{i})>0\end{array}\right.$$

##### 2.2 槽位识别

槽位抽取和其它业务场景最大的不同是，在我们的业务场景中有大量的地理位置识别，通过简单的NER模型显然是不能准确识别不同类型的地理位置类型，比如：行政区、商圈、小区等，所以这里就就通过NER+实体召回排序的的形式实现地理位置实体的识别，并同时实现纠错和实体链指，和知识图谱中的地理位置实体链接。 

#### 3. 对话状态管理

对话状态管理的目的是根据NLU的历史输出、对话进展、用户特征等维护和更新对话状态，并根据当前的会话状态，选择合适的动作。所以就设计到两个核心模块记录对话状态的DST模块，以及决定动作类型的对话策略模块。下面我们分别来介绍下这两个模块：

##### 3.1 对话状态追踪(DST)

目前在我们的业务场景中对话状态追踪主要应用于维护用户在对话过程中的找房需求语境下的状态，这里的状态追踪分成两类一类是可枚举的，一类是不可枚举的，对于价格、面积数值类型的我们都处理成分桶的可枚举数据，而对于地理位置类型由于数据量大，不可穷举，所以在状态追踪时对于地理位置类型的通过一些定制的规则判定是地理位置状态的增、删、改，而对于非地理位置的状态通过2019年发表的一篇文章，最终的DST的输出【此处有1个图表示dst的数据分布】SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking。

![image-20200714171831621](/Users/wangyongmei/Library/Application Support/typora-user-images/image-20200714171831621.png)

##### 3.2 对话策略(DP)

对话策略会结合NLU的识别结果、对话状态、上下文信息以及用户特征选择当前场景下最合适的动作，在我们的场景中线上实际使用的是规则+监督学习的方法，在小贝场景下房屋信息的动作就主要通过意图动作的映射对的形式识别，但对于找房、约带看等相对复杂的一些动作通过监督学习的方式识别，这里采用的模型结构是HAN，并结合t-1轮的对话状态信息识别当前经纪人应该执行什么动作。

【此处应有1图描述不同动作触发不同的task】

![image-20200714205721409](/Users/wangyongmei/Library/Application Support/typora-user-images/image-20200714205721409.png)

如果触发的是找房任务会根据当前dst的状态为用户寻找满足用户需求的房子，如果用户的需求还比较模糊，也会触发一些询问的话术，向用户澄清需求，以期为用户推荐出更为准确的房源。对于约带看等其他一些场景会触发NLG任务生成当前场景的一些话术，比如：“你啥时候有空，过来看看房？”。QaBot是相对复杂的场景，所以下面我们介绍下我们在QaBot上做的一些事情。

#### 4. QaBot

检索式对话可以解决当用户询问特定房源的特定信息的时候，为用户推送当前场景下最为契合的回答话术的问题，在我们的业务场景中我们把这个过程建模成了FAQ+知识图谱的问题，通过FAQ文本匹配系统推荐出来topN个话术模板，然后用知识图谱数据进行模板填充，这样既能保证答案的多样性，又可以通过FAQ库的构建保证答案与上文的自然衔接。对于这个系统而言最核心就是知识图谱、FAQ库、匹配系统，这里我们主要介绍下我们在FAQ库的构建以及文本匹配方面做的一些尝试。

![img](https://pic1.zhimg.com/80/v2-f3bc4f128c2b5595c6def4c70e2458ad_720w.jpg)

【此处应放一个QaBot的整体架构+并给出几个示例】

##### 4.1 FAQ库构建

【此处应该有1图描述FAQ数据构建】

对于FAQ库的构建而言，其实就是不断的生产query-answer对的过程，为了加速QA对的生产效率，我们一方面通过数据挖掘的方式从历史对话数据中挖掘符合条件的QA对，同时也会通过NLG的方式来生成QA对，然后把这些QA对，抽成业务模板，然后通过数据标注的形式确定是否可以入库。

https://zhuanlan.zhihu.com/p/83825070

##### 4.2 FAQ系统(KeMatch)

语义匹配的模型分为两大类一类是表示型、一类是交互型的，相比于表示型模型而言，交互型的深度匹配能很好地把握语义焦点，所以在业务中对比分析了交互型模型的效果，选用了ABCNN-1模型。

![image-20200714160114059](/Users/wangyongmei/Library/Application Support/typora-user-images/image-20200714160114059.png)

#### 5. 不局限于此



#### 6. 产品效果



#### 7. 总结 

